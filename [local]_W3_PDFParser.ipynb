{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Spire.PDF\n",
    "from spire.pdf.common import *\n",
    "from spire.pdf import *\n",
    "\n",
    "doc = PdfDocument()\n",
    "\n",
    "doc.LoadFromFile(\"/content/drive/MyDrive/CodeMely/Test1page.pdf\")\n",
    "\n",
    "doc.SaveToFile(\"PdfToHtml.html\", FileFormat.HTML)\n",
    "\n",
    "doc.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML Viewer: https://html.onlineviewer.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tôi thu được output 1: \n",
    "\n",
    "```\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"utf-8\"><title>PdfToHtml</title>\n",
    "</head>\n",
    "<body style='margin:0'>\n",
    "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" versyZgy51lJFLD130kmhv9y30LfQt9C30LeQPpEFlZgD+av/xA3EE9ACrAckASwBhAIQASAEWAaECGAHYAOMDFgGBAbcDngL8A/EBUgMlAlhaclpyWnJacgAEAAZAAQAsdkUgsAMlRSNhaBgjaGBELXjanVp7VFNntj/feQSliEJeAgKGEI6ZGCMJJxF5SRSMiGkmTXNTDDFiUMQHIiJShsulXIZS5Cq+peo4lLGOl+VYx1qlVu0ozlgW48wwXQ7X1auOo9a3F9sul8KX+52TCPGFgb9gEdb59vfbv/3bv71PMICFuosCXFQ5JscwEKrTqIUCQpZKaNRiHoGHxEzBmQQ+RfCkMbSWH8ck6ERiBrQf1AuOHgLHLDsa18+x6e9egwpTCr0Bzuh1VlbL9nzz/jhTDg5B5U8H8mFRcFtfqzG+CxrgeLhFPtMe3wFSYiF9IPFbsFdTGhuiicQxApsINxO/IXKwYGwCNhlFwhMKNOpUkkmQxlBaNqgAXBKDjmeIhFRcoxYJBcG4NCYO/M/H6ap8hzVNllgFG76Dnacvw\n",
    "\n",
    "...\n",
    "            <text style=\"fill:#0078C1;font-family:FF19;\" font-size=\"1\" transform=\"matrix(11 0 -0 11 925.7426 464.5177)\" fill-opacity=\"1\" x=\"0,0.522,0.849,1.162,1.688,2.21,2.4390001,2.766,3.079,3.613,4.1349998,4.943,5.27,5.794,6.0230002,6.545,6.872,7.295,7.829,8.351,8.6779995,9.101,9.635,10.157001,10.484,11.292,11.745,12.072\" y=\"0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\">ộ&#160;tuổi&#160;tham&#160;gia&#160;cho&#160;cha&#160;mẹ&#160;v</text>\n",
    "            <text style=\"fill:#0078C1;font-family:FF19;\" font-size=\"1\" transform=\"matrix(11 0 -0 11 1063.3516 464.5177)\" fill-opacity=\"1\" x=\"0,0.522,0.849\" y=\"0,0,0,0\">à&#160;c</text>\n",
    "            <text style=\"fill:#0078C1;font-family:FF19;\" font-size=\"1\" transform=\"matrix(11 0 -0 11 1077.2445 464.5177)\" fill-opacity=\"1\" x=\"0,0.522,1.056,1.383\" y=\"0,0,0,0,0\">on&#160;c</text>\n",
    "```\n",
    "\n",
    "Và code xử lý output1 \n",
    "```python\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html_to_text(html_content):\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all text elements\n",
    "    text_elements = soup.find_all('text')\n",
    "    \n",
    "    # Extract and combine text\n",
    "    full_text = ''\n",
    "    for element in text_elements:\n",
    "        # Extract x-coordinates and text content\n",
    "        x_coords = [float(x) for x in element.get('x', '').split(',') if x]\n",
    "        text_parts = element.text.split()\n",
    "        \n",
    "        # Ensure x_coords and text_parts have the same length\n",
    "        min_length = min(len(x_coords), len(text_parts))\n",
    "        x_coords = x_coords[:min_length]\n",
    "        text_parts = text_parts[:min_length]\n",
    "        \n",
    "        # Combine parts based on x-coordinates\n",
    "        for i, part in enumerate(text_parts):\n",
    "            if i > 0 and i < len(x_coords) and x_coords[i] - x_coords[i-1] > 1:  # Arbitrary threshold\n",
    "                full_text += ' '  # Add space for larger gaps\n",
    "            full_text += part\n",
    "        \n",
    "        full_text += ' '  # Space between different text elements\n",
    "    \n",
    "    # Clean up extra spaces and newlines\n",
    "    full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "    \n",
    "    # Join separated uppercase words\n",
    "    full_text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', full_text)\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "def post_process_text(text):\n",
    "    # Join single uppercase letters into words\n",
    "    text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', text)\n",
    "    \n",
    "    # Join words that are likely part of the same entity (e.g., \"Michig an\")\n",
    "    text = re.sub(r'(?<=\\w) (?=an\\b)', '', text)\n",
    "    text = re.sub(r'(?<=\\w) (?=v ersity\\b)', '', text)\n",
    "    \n",
    "    # Other specific joins based on common patterns in your text\n",
    "    text = text.replace(\"adv ersarial\", \"adversarial\")\n",
    "    text = text.replace(\"rob ustness\", \"robustness\")\n",
    "    text = text.replace(\"rob ustify\", \"robustify\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage and error handling\n",
    "try:\n",
    "    with open(r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\AI_Machine_Deep\\AI-ML-DL\\20232 NLP - M8 AIO\\2024_PDF_Parser_CODEMELY\\output_\\pdf2html.html', 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    cleaned_text = clean_html_to_text(html_content)\n",
    "    final_text = post_process_text(cleaned_text)\n",
    "    \n",
    "    print(\"Final processed text:\")\n",
    "    print(final_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "```\n",
    "\n",
    "-----------\n",
    "thu được output 2 \n",
    "\n",
    "```output2\n",
    "Final processed text:\n",
    "Published as a conference paper at ICLR 2022 HOWTOROBUSTIFYBLACK - BOXMLMODELS ? AZEROTH - ORDEROPTIMIZATIONPERSPECTIVEY imeng Zhang Michigan State Univ ersity Y uguang Y ao Michigan State Univ ersity Jinghan Jia Michigan State Univ ersity Jinfeng Y i JD AI Research Mingyi Hong Univ ersity of Minnesota Shiyu Chang UC Santa Barbara Sijia Liu Michigan State Univ ersity ABSTRACT The lack of adversarial robustness has been recognized asan important issue for state-of-the-art machine learning (ML) models, e.g., deep neural netw orks (DNNs) . Thereby , robustifying ML models ag ainst adversarial attacks is no w a major fo- cus of research. Ho we v er , nearly all e xisting defense methods, particularly for rob ust training, made the white-box assumption that the defender has t he access to the details ofan ML model (or its surrog ate alternati v es if a v ailable), e.g., its architectures and parameters. Be yond e xisting w orks, in this paper we aim to address the problem of blac k-box defense : Ho w to robustify a black-box model using just input queries and output feedback? Such a problem ari ses in practical scenarios, where the o wner of the predicti v e model is reluctant to share model information in order to preserv e pri v ac y . T o this end, we propose a general no- tion of defensi v e operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a ﬁrst-order (FO) certiﬁed de- fense technique. T o allo w the design of merely using model queries, we further inte grate DS with the zeroth-order (gradient-free) optimization. Ho we v er , a di- rect implementation of zeroth-order (ZO) optimization suf f ers a high v ariance of gradient estimates, and thus leads to inef fect i v e defense. T o tackle this problem, we ne xt propose to prependan autoencoder (AE) to a gi v en (black-box) model so that DS can be trained using v ariance-reduced ZO optimization. W e term the e v entual defense as ZO-AE-DS. In practice, we empirically sho w that ZO-AE- DS can achie v e impro v ed accurac y , certiﬁed robustness, and query comple xity o v er e xisting baselines. And the ef f ecti v eness of our approach is justiﬁed under both image classiﬁcation and image reconstruction tasks. Codes are a v ailable at https://github.com/damon-demon/Black-Box-Defense . 1 INTRODUCTION ML models , DNNs in particular , ha v e achie v ed remarkable success o wing to their superior predicti v e performance. Ho we v er , the y often lack robustness. F or e xample, imperceptible b ut carefully-crafted input perturbations can fool the decision of a well-trained ML model. These input perturbations refer to adver sarial perturbations , and the adversarially perturbed (test-time) e xamples are kno wn as adver sarial e xamples or adver sarial attac ks (Goodfello w et al., 2015; Carlini & W agner, 2017; P apernot et al., 2016). Existing studies ha v e sho wn that it is not dif ﬁcult to generate adversarial attacks. Numerous attack generation methods ha v e been designed and successfully applied to (i) dif ferent use cases from the digital w orld to the ph ysical w orld, e .g . , image classiﬁcation (Bro wn et al., 2017; Li et al., 2019; Xu et al., 2019; Y uan et al., 2021), object detection/tracking (Eykholt et al., 2017; Xu et al., 2020; Sun et al., 2020), and image reconstruction (Antun et al., 2020; Raj et al., 2020; V asilje vi ´ c et al., 2021), and (ii) dif ferent types of victim models, e .g . , white-box models whose details can be accessed by adv ersaries (Madry et al., 2018; Carlini & W agner, 2017; T ramer et al., 2020; Croce & Hein, 2020; W ang et al., 2021), and black-box models whose information is not disclosed to adv ersaries (P apernot et al., 2017; T u et al., 2019; Ilyas et al., 2018a; Liang et al., 2021). 1 Evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final processed text:\n",
      "Published as a conference paper at ICLR 2022 HOWTOROBUSTIFYBLACK - BOXMLMODELS ? AZEROTH - ORDEROPTIMIZATIONPERSPECTIVEY imeng Zhang Michigan State Univ ersity Y uguang Y ao Michigan State Univ ersity Jinghan Jia Michigan State Univ ersity Jinfeng Y i JD AI Research Mingyi Hong Univ ersity of Minnesota Shiyu Chang UC Santa Barbara Sijia Liu Michigan State Univ ersity ABSTRACT The lack of adversarial robustness has been recognized asan important issue for state-of-the-art machine learning (ML) models, e.g., deep neural netw orks (DNNs) . Thereby , robustifying ML models ag ainst adversarial attacks is no w a major fo- cus of research. Ho we v er , nearly all e xisting defense methods, particularly for rob ust training, made the white-box assumption that the defender has t he access to the details ofan ML model (or its surrog ate alternati v es if a v ailable), e.g., its architectures and parameters. Be yond e xisting w orks, in this paper we aim to address the problem of blac k-box defense : Ho w to robustify a black-box model using just input queries and output feedback? Such a problem ari ses in practical scenarios, where the o wner of the predicti v e model is reluctant to share model information in order to preserv e pri v ac y . T o this end, we propose a general no- tion of defensi v e operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a ﬁrst-order (FO) certiﬁed de- fense technique. T o allo w the design of merely using model queries, we further inte grate DS with the zeroth-order (gradient-free) optimization. Ho we v er , a di- rect implementation of zeroth-order (ZO) optimization suf f ers a high v ariance of gradient estimates, and thus leads to inef fect i v e defense. T o tackle this problem, we ne xt propose to prependan autoencoder (AE) to a gi v en (black-box) model so that DS can be trained using v ariance-reduced ZO optimization. W e term the e v entual defense as ZO-AE-DS. In practice, we empirically sho w that ZO-AE- DS can achie v e impro v ed accurac y , certiﬁed robustness, and query comple xity o v er e xisting baselines. And the ef f ecti v eness of our approach is justiﬁed under both image classiﬁcation and image reconstruction tasks. Codes are a v ailable at https://github.com/damon-demon/Black-Box-Defense . 1 INTRODUCTION ML models , DNNs in particular , ha v e achie v ed remarkable success o wing to their superior predicti v e performance. Ho we v er , the y often lack robustness. F or e xample, imperceptible b ut carefully-crafted input perturbations can fool the decision of a well-trained ML model. These input perturbations refer to adver sarial perturbations , and the adversarially perturbed (test-time) e xamples are kno wn as adver sarial e xamples or adver sarial attac ks (Goodfello w et al., 2015; Carlini & W agner, 2017; P apernot et al., 2016). Existing studies ha v e sho wn that it is not dif ﬁcult to generate adversarial attacks. Numerous attack generation methods ha v e been designed and successfully applied to (i) dif ferent use cases from the digital w orld to the ph ysical w orld, e .g . , image classiﬁcation (Bro wn et al., 2017; Li et al., 2019; Xu et al., 2019; Y uan et al., 2021), object detection/tracking (Eykholt et al., 2017; Xu et al., 2020; Sun et al., 2020), and image reconstruction (Antun et al., 2020; Raj et al., 2020; V asilje vi ´ c et al., 2021), and (ii) dif ferent types of victim models, e .g . , white-box models whose details can be accessed by adv ersaries (Madry et al., 2018; Carlini & W agner, 2017; T ramer et al., 2020; Croce & Hein, 2020; W ang et al., 2021), and black-box models whose information is not disclosed to adv ersaries (P apernot et al., 2017; T u et al., 2019; Ilyas et al., 2018a; Liang et al., 2021). 1 Evaluation\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html_to_text(html_content):\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all text elements\n",
    "    text_elements = soup.find_all('text')\n",
    "    \n",
    "    # Extract and combine text\n",
    "    full_text = ''\n",
    "    for element in text_elements:\n",
    "        # Extract x-coordinates and text content\n",
    "        x_coords = [float(x) for x in element.get('x', '').split(',') if x]\n",
    "        text_parts = element.text.split()\n",
    "        \n",
    "        # Ensure x_coords and text_parts have the same length\n",
    "        min_length = min(len(x_coords), len(text_parts))\n",
    "        x_coords = x_coords[:min_length]\n",
    "        text_parts = text_parts[:min_length]\n",
    "        \n",
    "        # Combine parts based on x-coordinates\n",
    "        for i, part in enumerate(text_parts):\n",
    "            if i > 0 and i < len(x_coords) and x_coords[i] - x_coords[i-1] > 1:  # Arbitrary threshold\n",
    "                full_text += ' '  # Add space for larger gaps\n",
    "            full_text += part\n",
    "        \n",
    "        full_text += ' '  # Space between different text elements\n",
    "    \n",
    "    # Clean up extra spaces and newlines\n",
    "    full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "    \n",
    "    # Join separated uppercase words\n",
    "    full_text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', full_text)\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "def post_process_text(text):\n",
    "    # Join single uppercase letters into words\n",
    "    text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', text)\n",
    "    \n",
    "    # Join words that are likely part of the same entity (e.g., \"Michig an\")\n",
    "    text = re.sub(r'(?<=\\w) (?=an\\b)', '', text)\n",
    "    text = re.sub(r'(?<=\\w) (?=v ersity\\b)', '', text)\n",
    "    \n",
    "    # Other specific joins based on common patterns in your text\n",
    "    text = text.replace(\"adv ersarial\", \"adversarial\")\n",
    "    text = text.replace(\"rob ustness\", \"robustness\")\n",
    "    text = text.replace(\"rob ustify\", \"robustify\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage and error handling\n",
    "try:\n",
    "    with open(r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\AI_Machine_Deep\\AI-ML-DL\\20232 NLP - M8 AIO\\2024_PDF_Parser_CODEMELY\\output_\\pdf2html.html', 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    cleaned_text = clean_html_to_text(html_content)\n",
    "    final_text = post_process_text(cleaned_text)\n",
    "    \n",
    "    print(\"Final processed text:\")\n",
    "    print(final_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final processed text:\n",
      "Published as a conference paper at ICLR 2022 HOWTOROBUSTIFYBLACK - BOXMLMODELS? AZEROTH - ORDEROPTIMIZATIONPERSPECTIVEY imeng Zhang Michigan State University Y uguang Y ao Michigan State University Jinghan Jia Michigan State University Jinfeng Y i JD AI Research Mingyi Hong University of Minnesota Shiyu Chang UC Santa Barbara Sijia Liu Michigan State University ABSTRACT The lack of adversarial robustness has been recognized asan important issue for state-of-the-art machine learning (ML) models, e.g., deep neural netw orks (DNNs). Thereby, robustifying ML models ag ainst adversarial attacks is no w a major fo- cus of research. Ho we v er, nearly all e xisting defense methods, particularly for rob ust training, made the white-box assumption that the defender has t he access to the details ofan ML model (or its surrog ate alternati v es if a v ailable), e.g., its architectures and parameters. Be yond e xisting w orks, in this paper we aim to address the problem of blac k-box defense: Ho w to robustify a black-box model using just input queries and output feedback? Such a problem ari ses in practical scenarios, where the o wner of the predicti v e model is reluctant to share model information in order to preserv e pri v ac y. T o this end, we propose a general no- tion of defensi v e operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a ﬁrst-order (FO) certiﬁed de- fense technique. T o allo w the design of merely using model queries, we further inte grate DS with the zeroth-order (gradient-free) optimization. Ho we v er, a di- rect implementation of zeroth-order (ZO) optimization suf f ers a high v ariance of gradient estimates, and thus leads to inef fect i v e defense. T o tackle this problem, we ne xt propose to prependan autoencoder (AE) to a gi v en (black-box) model so that DS can be trained using v ariance-reduced ZO optimization. W e term the e v entual defense as ZO-AE-DS. In practice, we empirically sho w that ZO-AE- DS can achie v e impro v ed accurac y, certiﬁed robustness, and query comple xity o v er e xisting baselines. And the ef f ecti v eness of our approach is justiﬁed under both image classiﬁcation and image reconstruction tasks. Codes are a v ailable at https://github.com/damon-demon/Black-Box-Defense. 1 INTRODUCTION ML models, DNNs in particular, ha v e achie v ed remarkable success o wing to their superior predicti v e performance. Ho we v er, the y often lack robustness. F or e xample, imperceptible b ut carefully-crafted input perturbations can fool the decision of a well-trained ML model. These input perturbations refer to adver sarial perturbations, and the adversarially perturbed (test-time) e xamples are kno wn as adver sarial e xamples or adver sarial attac ks (Goodfello w et al., 2015; Carlini & W agner, 2017; P apernot et al., 2016). Existing studies ha v e sho wn that it is not dif ﬁcult to generate adversarial attacks. Numerous attack generation methods ha v e been designed and successfully applied to (i) dif ferent use cases from the digital w orld to the ph ysical w orld, e.g., image classiﬁcation (Bro wn et al., 2017; Li et al., 2019; Xu et al., 2019; Y uan et al., 2021), object detection/tracking (Eykholt et al., 2017; Xu et al., 2020; Sun et al., 2020), and image reconstruction (Antun et al., 2020; Raj et al., 2020; V asilje vi ´ c et al., 2021), and (ii) dif ferent types of victim models, e.g., white-box models whose details can be accessed by adv ersaries (Madry et al., 2018; Carlini & W agner, 2017; T ramer et al., 2020; Croce & Hein, 2020; W ang et al., 2021), and black-box models whose information is not disclosed to adv ersaries (P apernot et al., 2017; T u et al., 2019; Ilyas et al., 2018a; Liang et al., 2021). 1 Evaluation\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html_to_text(html_content):\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all text elements\n",
    "    text_elements = soup.find_all('text')\n",
    "    \n",
    "    # Extract and combine text\n",
    "    full_text = ''\n",
    "    for element in text_elements:\n",
    "        # Extract x-coordinates and text content\n",
    "        x_coords = [float(x) for x in element.get('x', '').split(',') if x]\n",
    "        text_parts = element.text.split()\n",
    "        \n",
    "        # Ensure x_coords and text_parts have the same length\n",
    "        min_length = min(len(x_coords), len(text_parts))\n",
    "        x_coords = x_coords[:min_length]\n",
    "        text_parts = text_parts[:min_length]\n",
    "        \n",
    "        # Combine parts based on x-coordinates\n",
    "        for i, part in enumerate(text_parts):\n",
    "            if i > 0 and i < len(x_coords) and x_coords[i] - x_coords[i-1] > 1:  # Arbitrary threshold\n",
    "                full_text += ' '  # Add space for larger gaps\n",
    "            full_text += part\n",
    "        \n",
    "        full_text += ' '  # Space between different text elements\n",
    "    \n",
    "    # Clean up extra spaces and newlines\n",
    "    full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "def post_process_text(text):\n",
    "    # Join single uppercase letters into words\n",
    "    text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', text)\n",
    "    \n",
    "    # Join words that are likely part of the same entity (e.g., \"Michig an\")\n",
    "    text = re.sub(r'(?<=\\w) (?=an\\b)', '', text)\n",
    "    text = re.sub(r'(?<=\\w) (?=v ersity\\b)', '', text)\n",
    "    \n",
    "    # Additional specific joins based on common patterns in your text\n",
    "    text = text.replace(\"adv ersarial\", \"adversarial\")\n",
    "    text = text.replace(\"rob ustness\", \"robustness\")\n",
    "    text = text.replace(\"rob ustify\", \"robustify\")\n",
    "    text = text.replace(\"Univ ersity\", \"University\")\n",
    "    text = text.replace(\"v ersity\", \"versity\")\n",
    "    \n",
    "    # Removing unnecessary spaces before punctuation\n",
    "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "\n",
    "    # Fix known issues (like URL issues)\n",
    "    text = re.sub(r'https ://', 'https://', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage and error handling\n",
    "try:\n",
    "    with open(r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\AI_Machine_Deep\\AI-ML-DL\\20232 NLP - M8 AIO\\2024_PDF_Parser_CODEMELY\\output_\\pdf2html.html', 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    cleaned_text = clean_html_to_text(html_content)\n",
    "    final_text = post_process_text(cleaned_text)\n",
    "    \n",
    "    print(\"Final processed text:\")\n",
    "    print(final_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final processed text:\n",
      "Published as a conference paper at ICLR 2022 HOWTOROBUSTIFYBLACK - BOXMLMODELS? AZEROTH - ORDEROPTIMIZATIONPERSPECTIVEY imeng Zhang Michig an State Uni versity Y uguang Y ao Michig an State Uni versity Jinghan Jia Michig an State Uni versity Jinfeng Y i JD AI Research Mingyi Hong Uni versity of Minnesota Shiyu Chang UC Santa Barbara Sijia Liu Michig an State Uni versity ABSTRACT The lack of adversarial robustness has been recognized as an important issue for state-of-the-art machine learning (ML) models, e.g., deep neural netw orks (DNNs). Thereby, robustifying ML models ag ainst adversarial attacks is no w a major fo- cus of research. Ho we v er, nearly all e xisting defense methods, particularly for rob ust training, made the white-box assumption that the defender has t he access to the details of an ML model (or its surrog ate alternati v es if a v ailable), e.g., its architectures and parameters. Be yond e xisting w orks, in this paper we aim to address the problem of blac k-box defense: Ho w to robustify a black-box model using just input queries and output feedback? Such a problem ari ses in practical scenarios, where the o wner of the predictive model is reluctant to share model information in order to preserv e pri v ac y. T o this end, we propose a general no- tion of defensi v e operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a ﬁrst-order (FO) certiﬁed de- fense technique. T o allo w the design of merely using model queries, we further inte grate DS with the zeroth-order (gradient-free) optimization. Ho we v er, a di- rect implementation of zeroth-order (ZO) optimization suf f ers a high v ariance of gradient estimates, and thus leads to inef fect i v e defense. T o tackle this problem, we ne xt propose to prepend an autoencoder (AE) to a gi v en (black-box) model so that DS can be trained using v ariance-reduced ZO optimization. W e term the e v entual defense as ZO-AE-DS. In practice, we empirically sho w that ZO-AE- DS can achie v e impro v ed accurac y, certiﬁed robustness, and query comple xity o v er e xisting baselines. And the ef f ecti v eness of our approach is justiﬁed under both image classiﬁcation and image reconstruction tasks. Codes are a v ailable at https://github.com/damon-demon/Black-Box-Defense. 1 INTRODUCTION ML models, DNNs in particular, ha v e achie v ed remarkable success o wing to their superior predictive performance. Ho we v er, the y often lack robustness. F or e xample, imperceptible b ut carefully-crafted input perturbations can fool the decision of a well-trained ML model. These input perturbations refer to adversarial perturbations, and the adversarially perturbed (test-time) e xamples are kno wn as adversarial e xamples or adversarial attac ks (Goodfello w et al., 2015; Carlini & W agner, 2017; P apernot et al., 2016). Existing studies ha v e sho wn that it is not dif ﬁcult to generate adversarial attacks. Numerous attack generation methods ha v e been designed and successfully applied to (i) dif ferent use cases from the digital w orld to the ph ysical w orld, e.g., image classiﬁcation (Bro wn et al., 2017; Li et al., 2019; Xu et al., 2019; Y uan et al., 2021), object detection/tracking (Eykholt et al., 2017; Xu et al., 2020; Sun et al., 2020), and image reconstruction (Antun et al., 2020; Raj et al., 2020; V asilje vi ´ c et al., 2021), and (ii) dif ferent types of victim models, e.g., white-box models whose details can be accessed by adv ersaries (Madry et al., 2018; Carlini & W agner, 2017; T ramer et al., 2020; Croce & Hein, 2020; W ang et al., 2021), and black-box models whose information is not disclosed to adv ersaries (P apernot et al., 2017; T u et al., 2019; Ilyas et al., 2018a; Liang et al., 2021). 1 Evaluation\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Hàm làm sạch HTML và chuyển đổi thành văn bản\n",
    "def clean_html_to_text(html_content):\n",
    "    # Phân tích cú pháp HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Tìm tất cả các phần tử <text> trong HTML\n",
    "    text_elements = soup.find_all('text')\n",
    "    \n",
    "    # Chuỗi để chứa toàn bộ văn bản kết hợp\n",
    "    full_text = ''\n",
    "    \n",
    "    # Lặp qua từng phần tử văn bản\n",
    "    for element in text_elements:\n",
    "        # Trích xuất tọa độ x và nội dung văn bản từ phần tử\n",
    "        x_coords = [float(x) for x in element.get('x', '').split(',') if x]  # Lấy tọa độ x, chuyển thành danh sách số thực\n",
    "        text_content = element.get_text(separator=\" \")  # Lấy nội dung văn bản, các từ được ngăn cách bằng khoảng trắng\n",
    "\n",
    "        # Nếu có tọa độ x\n",
    "        if x_coords:\n",
    "            last_x = x_coords[0]  # Lấy tọa độ x đầu tiên\n",
    "            for i, (x, part) in enumerate(zip(x_coords, text_content.split())):\n",
    "                # Nếu khoảng cách giữa các tọa độ x lớn hơn ngưỡng (1 ở đây), thêm khoảng trắng\n",
    "                if i > 0 and x - last_x > 1:  # Ngưỡng tùy ý là 1\n",
    "                    full_text += ' '  # Thêm khoảng trắng\n",
    "                full_text += part  # Thêm phần văn bản vào chuỗi kết hợp\n",
    "                last_x = x  # Cập nhật tọa độ x cuối cùng\n",
    "        else:\n",
    "            full_text += text_content  # Nếu không có tọa độ x, chỉ thêm nội dung văn bản\n",
    "        \n",
    "        full_text += ' '  # Thêm khoảng trắng giữa các phần tử văn bản khác nhau\n",
    "    \n",
    "    # Làm sạch khoảng trắng và xuống dòng thừa\n",
    "    full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "# Hàm xử lý hậu kỳ văn bản để loại bỏ lỗi\n",
    "def post_process_text(text):\n",
    "    # Kết hợp các chữ cái viết hoa đơn lẻ thành từ\n",
    "    text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', text)\n",
    "    \n",
    "    # Sửa các lỗi phân tách từ phổ biến\n",
    "    fixes = {\n",
    "        \"adv ersarial\": \"adversarial\",\n",
    "        \"rob ustness\": \"robustness\",\n",
    "        \"rob ustify\": \"robustify\",\n",
    "        \"Univ ersity\": \"University\",\n",
    "        \"v ersity\": \"versity\",\n",
    "        \"adver sarial\": \"adversarial\",\n",
    "        \"predicti v e\": \"predictive\",\n",
    "        \"certiﬁ ed\": \"certified\",\n",
    "        \"respon sive\": \"responsive\",\n",
    "        \"decisi on\": \"decision\",\n",
    "        \"gener al\": \"general\",\n",
    "        \"imp act\": \"impact\"\n",
    "    }\n",
    "    \n",
    "    for k, v in fixes.items():\n",
    "        text = text.replace(k, v)  # Thay thế các lỗi phân tách từ bằng từ đúng\n",
    "    \n",
    "    # Loại bỏ khoảng trắng không cần thiết trước dấu câu\n",
    "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "    \n",
    "    # Sửa các lỗi URL đã biết\n",
    "    text = re.sub(r'https ://', 'https://', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Ví dụ sử dụng và xử lý lỗi\n",
    "try:\n",
    "    # Đọc nội dung HTML từ tệp\n",
    "    with open(r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\AI_Machine_Deep\\AI-ML-DL\\20232 NLP - M8 AIO\\2024_PDF_Parser_CODEMELY\\output_\\pdf2html.html', 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()  # Đọc nội dung tệp HTML\n",
    "\n",
    "    # Làm sạch nội dung HTML và chuyển đổi thành văn bản\n",
    "    cleaned_text = clean_html_to_text(html_content)\n",
    "    # Xử lý hậu kỳ văn bản để loại bỏ lỗi\n",
    "    final_text = post_process_text(cleaned_text)\n",
    "    \n",
    "    # In ra văn bản cuối cùng đã xử lý\n",
    "    print(\"Final processed text:\")\n",
    "    print(final_text)\n",
    "\n",
    "except Exception as e:\n",
    "    # In ra lỗi nếu có xảy ra\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: \n",
      "\n",
      "You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15708\\2623450390.py\", line 84, in <module>\n",
      "    final_text = post_process_text(cleaned_text)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15708\\2623450390.py\", line 47, in post_process_text\n",
      "    response = openai.Completion.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\lib\\_old_api.py\", line 39, in __call__\n",
      "    raise APIRemovedInV1(symbol=self._symbol)\n",
      "openai.lib._old_api.APIRemovedInV1: \n",
      "\n",
      "You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import openai\n",
    "\n",
    "# Hàm làm sạch HTML và chuyển đổi thành văn bản\n",
    "def clean_html_to_text(html_content):\n",
    "    # Phân tích cú pháp HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Tìm tất cả các phần tử <text> trong HTML\n",
    "    text_elements = soup.find_all('text')\n",
    "    \n",
    "    # Chuỗi để chứa toàn bộ văn bản kết hợp\n",
    "    full_text = ''\n",
    "    \n",
    "    # Lặp qua từng phần tử văn bản\n",
    "    for element in text_elements:\n",
    "        # Trích xuất tọa độ x và nội dung văn bản từ phần tử\n",
    "        x_coords = [float(x) for x in element.get('x', '').split(',') if x]  # Lấy tọa độ x, chuyển thành danh sách số thực\n",
    "        text_content = element.get_text(separator=\" \")  # Lấy nội dung văn bản, các từ được ngăn cách bằng khoảng trắng\n",
    "\n",
    "        # Nếu có tọa độ x\n",
    "        if x_coords:\n",
    "            last_x = x_coords[0]  # Lấy tọa độ x đầu tiên\n",
    "            for i, (x, part) in enumerate(zip(x_coords, text_content.split())):\n",
    "                # Nếu khoảng cách giữa các tọa độ x lớn hơn ngưỡng (1 ở đây), thêm khoảng trắng\n",
    "                if i > 0 and x - last_x > 1:  # Ngưỡng tùy ý là 1\n",
    "                    full_text += ' '  # Thêm khoảng trắng\n",
    "                full_text += part  # Thêm phần văn bản vào chuỗi kết hợp\n",
    "                last_x = x  # Cập nhật tọa độ x cuối cùng\n",
    "        else:\n",
    "            full_text += text_content  # Nếu không có tọa độ x, chỉ thêm nội dung văn bản\n",
    "        \n",
    "        full_text += ' '  # Thêm khoảng trắng giữa các phần tử văn bản khác nhau\n",
    "    \n",
    "    # Làm sạch khoảng trắng và xuống dòng thừa\n",
    "    full_text = re.sub(r'\\s+', ' ', full_text).strip()\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "# Hàm xử lý hậu kỳ văn bản để loại bỏ lỗi, sử dụng GPT-3.5 để nhận diện lỗi phân tách từ\n",
    "def post_process_text(text):\n",
    "    # Kết hợp các chữ cái viết hoa đơn lẻ thành từ\n",
    "    text = re.sub(r'(?<=\\b[A-Z]) (?=[A-Z]\\b)', '', text)\n",
    "    \n",
    "    # Sử dụng GPT-3.5 để nhận diện các lỗi phân tách từ phổ biến\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=f\"Identify common word separation errors in the following text and provide corrections:\\n\\n{text}\",\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Nhận danh sách các lỗi và sửa chữa từ GPT-3.5\n",
    "    fixes = {}\n",
    "    if response and 'choices' in response and response['choices']:\n",
    "        corrections = response['choices'][0]['text'].strip().split('\\n')\n",
    "        for correction in corrections:\n",
    "            if '=>' in correction:\n",
    "                parts = correction.split('=>')\n",
    "                if len(parts) == 2:\n",
    "                    fixes[parts[0].strip()] = parts[1].strip()\n",
    "\n",
    "    # Sửa các lỗi phân tách từ dựa trên danh sách nhận được\n",
    "    for k, v in fixes.items():\n",
    "        text = text.replace(k, v)  # Thay thế các lỗi phân tách từ bằng từ đúng\n",
    "    \n",
    "    # Loại bỏ khoảng trắng không cần thiết trước dấu câu\n",
    "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "    \n",
    "    # Sửa các lỗi URL đã biết\n",
    "    text = re.sub(r'https ://', 'https://', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Ví dụ sử dụng và xử lý lỗi\n",
    "try:\n",
    "    # Đọc nội dung HTML từ tệp\n",
    "    with open(r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\AI_Machine_Deep\\AI-ML-DL\\20232 NLP - M8 AIO\\2024_PDF_Parser_CODEMELY\\output_\\pdf2html.html', 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()  # Đọc nội dung tệp HTML\n",
    "\n",
    "    # Làm sạch nội dung HTML và chuyển đổi thành văn bản\n",
    "    cleaned_text = clean_html_to_text(html_content)\n",
    "    # Xử lý hậu kỳ văn bản để loại bỏ lỗi\n",
    "    final_text = post_process_text(cleaned_text)\n",
    "    \n",
    "    # In ra văn bản cuối cùng đã xử lý\n",
    "    print(\"Final processed text:\")\n",
    "    print(final_text)\n",
    "\n",
    "except Exception as e:\n",
    "    # In ra lỗi nếu có xảy ra\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
